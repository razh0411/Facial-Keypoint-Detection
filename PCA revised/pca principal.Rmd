---
title: "pca - principal"
output: html_document
---

```{r}
library(doMC)
registerDoMC()
library(reshape2)
library(psych)
```

# Data:

```{r, echo=FALSE}
d.train <- read.csv("/Users/ran/Desktop/MA 676/Data Competition/training.csv",stringsAsFactors=F)
d.test <- read.csv("/Users/ran/Desktop/MA 676/Data Competition/test.csv",stringsAsFactors=F)
im.test    <- foreach(im = d.test$Image, .combine=rbind) %dopar% {
  as.integer(unlist(strsplit(im, " ")))
}

```

# PCA - components

```{r,echo=FALSE}
row.has.na <- apply(d.train, 1, function(x){any(is.na(x))})
sum(row.has.na) # rows those have missing values
d.train.s <- d.train[!row.has.na,] # NO MISSING 
im.train.s   <- foreach(im = d.train.s$Image, .combine=rbind) %dopar% {
  as.integer(unlist(strsplit(im, " ")))
} # NO MISSING 


# First 136: eigenvalue > 1
comp <- summary(princomp(~t(im.train.s),cor=T))
comp
prin <- principal(t(im.train.s),nfactors=136,rotate="varimax")#?????????????????????image?????????PC???loading??????

##### choose all the PC (first 21) which has loadings larger than 0.5, based on these, return the #id of rows, make a new data frame, and compute mean for each col (for each keypoint)
#mean.frame<-data.frame()
#prin.loading.matrix<-data.frame()
#for(j in 1:30){
#for (i in 1:21){
#  mean.frame[j,i]<-mean(d.train.s[which(abs(prin$loadings[,i])>=0.5),j])
#  matrix.mean<-t(mean.frame)
#  points30.mean<-colMeans(matrix.mean)
#
#}
#}
## 21???PC????????????0??? out of 136 PCs???


# mean(d.train.s[which(prin$loadings[,1]>0.5),1])
# mean col.1 = 66.19671
# Only using the rows that have 50%+ loadings on PC1 to make a dataframe
#pca.d.train.s<-d.train.s[which(prin$loadings[,1]>=0.5),]
# pca.d.train.s is the matrix for all cols which their loadings on PC1 > 0.5
# Use rows that have 50% + loading s on PC 1 ~ 21 to make a dataframe

#pca.d.train.s<-d.train.s
#for (i in 1:21){
#     pca.d.train.s<-pca.d.train.s[-which(prin$loadings[,i]>=0.5),]
#}# 689rows with 31cols which have nothing larger than 0.5 from PC1-->PC21


###### Coordinates Data File ######
# Use PC1 - PC21, and select those rows that have the loadings larger or equal to 0.5
# Store those rows into a new data.frame
##### threshold accumulated proportion = 80% ####

apply(prin$loadings,1,abs)->abs.loadings  # 1 = rows ; while 2 = cols    # overall 136 columns
apply(abs.loadings,2,max)->max.abs.loadings
max.obs.loadings0.5<-(max.abs.loadings>=0.5)
sum(max.obs.loadings0.5==T)
pca136.d.train.s<-d.train.s[which(max.obs.loadings0.5==T),]  # dim= 11660   31

######## Image Data #########
# exclude the image col from pca.d.train.s dataset
pca136.d.train.s$Image<-NULL
# we use this dataset to compute the mean coordinates for each col
# accordingly, we restore image dataset which has equal # of rows to pca.d.train.s
pca136.im.train.s<- im.train.s[which(max.obs.loadings0.5==T),]
dim(pca136.im.train.s) # 1660 9216

```


```{r,echo=FALSE}
## the keypoint we want to predict
coordinate.names <- gsub("_x", "", names(pca136.d.train.s)[grep("_x", names(d.train))])

patch_size <- 10

########### First example: when search_size = 1 ###############
search_size <- 3

# for each one, compute the average patch
mean.patches <- foreach(coord = coordinate.names) %dopar% {
  cat(sprintf("computing mean patch for %s\n", coord))
  coord_x <- paste(coord, "x", sep="_")
  coord_y <- paste(coord, "y", sep="_")
  
  # compute average patch
  patches <- foreach (i = 1:nrow(pca136.d.train.s), .combine=rbind) %do% {
    im  <- matrix(data = pca136.im.train.s[i,], nrow=96, ncol=96)
    x   <- pca136.d.train.s[i, coord_x]
    y   <- pca136.d.train.s[i, coord_y]
    x1  <- (x-patch_size)
    x2  <- (x+patch_size)
    y1  <- (y-patch_size)
    y2  <- (y+patch_size)
    if ( (!is.na(x)) && (!is.na(y)) && (x1>=1) && (x2<=96) && (y1>=1) && (y2<=96) )
    {
      as.vector(im[x1:x2, y1:y2])
    }
    else
    {
      NULL
    }
  }
  matrix(data = colMeans(patches), nrow=2*patch_size+1, ncol=2*patch_size+1)
}

######    not for submission    ########
# plot left eye_center as example
coord      <- "left_eye_center"
patch_size <- 10
coord_x <- paste(coord, "x", sep="_")
coord_y <- paste(coord, "y", sep="_")
patches <- foreach (i = 1:nrow(pca136.d.train.s), .combine=rbind) %do% {
    im  <- matrix(data = pca136.im.train.s[i,], nrow=96, ncol=96)
    x   <- pca136.d.train.s[i, coord_x]
    y   <- pca136.d.train.s[i, coord_y]
    x1  <- (x-patch_size)
    x2  <- (x+patch_size)
    y1  <- (y-patch_size)
    y2  <- (y+patch_size)
    if ( (!is.na(x)) && (!is.na(y)) && (x1>=1) && (x2<=96) && (y1>=1) && (y2<=96) )
    {
        as.vector(im[x1:x2, y1:y2])
    }
    else
    {
        NULL
    }
}
plot.mean.patch <- matrix(data = colMeans(patches), nrow=2*patch_size+1, ncol=2*patch_size+1)
image(1:21, 1:21, plot.mean.patch[21:1,21:1], col=gray((0:255)/255))
#####################################
```


```{r,echo=FALSE}
# for each coordinate and for each test image, find the position that best correlates with the average patch
p <- foreach(coord_i = 1:length(coordinate.names), .combine=cbind) %dopar% {
  # the coordinates we want to predict
  coord   <- coordinate.names[coord_i]
  coord_x <- paste(coord, "x", sep="_")
  coord_y <- paste(coord, "y", sep="_")
  
  # the average of them in the training set (our starting point)
  mean_x  <- mean(pca136.d.train.s[, coord_x], na.rm=T)
  mean_y  <- mean(pca136.d.train.s[, coord_y], na.rm=T)
  
  # search space: 'search_size' pixels centered on the average coordinates 
  x1 <- as.integer(mean_x)-search_size
  x2 <- as.integer(mean_x)+search_size
  y1 <- as.integer(mean_y)-search_size
  y2 <- as.integer(mean_y)+search_size
  
  # ensure we only consider patches completely inside the image
  x1 <- ifelse(x1-patch_size<1,  patch_size+1,  x1)
  y1 <- ifelse(y1-patch_size<1,  patch_size+1,  y1)
  x2 <- ifelse(x2+patch_size>96, 96-patch_size, x2)
  y2 <- ifelse(y2+patch_size>96, 96-patch_size, y2)
  
  # build a list of all positions to be tested
  params <- expand.grid(x = x1:x2, y = y1:y2)
  
  # for each image...
  r <- foreach(i = 1:nrow(d.test), .combine=rbind) %do% {
    if ((coord_i==1)&&((i %% 100)==0)) { cat(sprintf("%d/%d\n", i, nrow(d.test))) }
    im <- matrix(data = im.test[i,], nrow=96, ncol=96)
    
    # ... compute a score for each position ...
    r  <- foreach(j = 1:nrow(params), .combine=rbind) %do% {
      x     <- params$x[j]
      y     <- params$y[j]
      p     <- im[(x-patch_size):(x+patch_size), (y-patch_size):(y+patch_size)]
      score <- cor(as.vector(p), as.vector(mean.patches[[coord_i]]))
      score <- ifelse(is.na(score), 0, score)
      data.frame(x, y, score)
    }
    
    # ... and return the best
    best <- r[which.max(r$score), c("x", "y")]
  }
  names(r) <- c(coord_x, coord_y)
  r
}

########### not for submission ##########
# compute our RMSE
p <- matrix(data=colMeans(pca136.d.train.s, na.rm=T), nrow=nrow(d.test), ncol=ncol(pca136.d.train.s), byrow=T)
sqrt(mean((d.test-p)^2, na.rm=T))
```

# Make a submission

```{r,echo=FALSE}
predictions        <- data.frame(ImageId = 1:nrow(d.test), p)
write.table(predictions, "/Users/ran/Desktop/pca with imp. comp/predicted location.csv")
submission         <- melt(predictions, id.vars="ImageId", variable.name="FeatureName", value.name="Location")
example.submission <- read.csv("/Users/wangjianing/Documents/Boston U/BU/spring 2016/MA 676/kaggle competition/IdLookupTable.csv")
sub.col.names      <- names(example.submission)
example.submission$Location <- NULL

submission <- merge(example.submission, submission, all.x=T, sort=F)
submission <- submission[, sub.col.names]

write.csv(submission, file="pca_submission.csv", quote=F, row.names=F)
write.table(submission, "/Users/wangjianing/Desktop/pca_submission.csv", sep="\t")
```

# Test Image 

```{r,echo=FALSE}
########### Plot from test data and predicted location

# 1. original image in test data 
test <- read.csv("/Users/ran/Desktop/MA 676/Data Competition/test.csv",stringsAsFactors=F)
im.test <- foreach(im = test$Image, .combine = rbind) %dopar% {
  as.integer(unlist(strsplit(im, " ")))
}
im <- matrix(data=rev(im.test[575,]), nrow=96, ncol=96) # 575 and 502
image(1:96, 1:96, im, col=gray((0:255)/255))

# 2. The predicted location in the submission file
submission <- read.csv("/Users/ran/Desktop/pca with imp. comp/predicted location.csv",sep=",")
for(i in 1:nrow(submission)) {
  points(96-submission$right_eyebrow_inner_end_x[i], 96-submission$right_eyebrow_inner_end_y[i], col="red")
}

# 3. check the maximum of one keypoint and plot the image, then find the location in this image 
idx <- which.max(submission$right_eye_center_y)
im  <- matrix(data=rev(im.test[idx,]), nrow=96, ncol=96)
image(1:96, 1:96, im, col=gray((0:255)/255))
points(96-submission$left_eye_center_x[idx], 96-submission$left_eye_center_y[idx], col="red")

 

